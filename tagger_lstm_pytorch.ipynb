{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM  in PyTorch\n",
    "\n",
    "The input_size argument to any RNN says how many features will there be for each step in a sequence, not what it's length is going to be. Keras uses static graphs, so it needs to know the length of the sequence upfront, PyTorch has dynamic autodifferentiation so it doesn't care about the sequence length - you can use a different one every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSTM(input_size = num features, hidden_size, num_layers)\n",
    "rnn = nn.LSTM(2, 10, 1)\n",
    "\n",
    "# input (seq_len = num timesteps, batch, input_size = num_features)\n",
    "input = Variable(torch.randn(4, 3, 2))\n",
    "output, hn = rnn(input)\n",
    "\n",
    "#print(input)\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "see also https://github.com/moskomule/pytorch.learning/blob/master/src/lstm_text_gen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input = [\"5h slides für Statistik-Kurs\",\n",
    "#         \"3h Präsi für DOAG\",\n",
    "#         \"Apps: Impl 3 h\",\n",
    "#         \"NP, Impl new feature\",\n",
    "#        ]\n",
    "#input_lists = [word_tokenize(s) for s in input]\n",
    "#print(input_lists)\n",
    "\n",
    "#tags = [[\"duration\", \"what\", \"SEP\", \"project\"],\n",
    "#        [\"duration\", \"what\", \"SEP\", \"project\"],\n",
    "#        [\"project\", \"SEP\", \"what\", \"duration\", \"duration\"],\n",
    "#        [\"project\", \"SEP\", \"what\", \"what\", \"what\"]\n",
    "#       ]\n",
    "\n",
    "#training_data = list(zip(input_lists, tags))\n",
    "#training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word_to_ix = {}\n",
    "#for lst in input_lists:\n",
    "#    for word in lst:\n",
    "#        if word not in word_to_ix:\n",
    "#            word_to_ix[word] = len(word_to_ix)\n",
    "#\n",
    "#tag_to_ix = {\"duration\": 0, \"what\": 1, \"project\": 2, \"SEP\": 3}\n",
    "#\n",
    "#print(word_to_ix)\n",
    "#print(tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 25,\n",
       " '1d': 9,\n",
       " '30_Min': 11,\n",
       " '3h': 8,\n",
       " '5_Std': 10,\n",
       " '8h': 7,\n",
       " ':': 24,\n",
       " 'Angular': 1,\n",
       " 'Apex': 2,\n",
       " 'Auswertung': 20,\n",
       " 'Authentifizierung': 0,\n",
       " 'DOAG_Vortrag': 4,\n",
       " 'DS-R-L': 5,\n",
       " 'Impl': 13,\n",
       " 'Implementierung': 16,\n",
       " 'MySQL_PoC': 3,\n",
       " 'New_Features': 19,\n",
       " 'Planung': 14,\n",
       " 'Präsi': 21,\n",
       " 'Recherche': 15,\n",
       " 'Sentimentanalyse': 6,\n",
       " 'Slides': 12,\n",
       " 'Tests': 17,\n",
       " 'Unit_Tests': 18,\n",
       " 'auf': 23,\n",
       " 'für': 22}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no spaces just for data generation; in reality we will anyway tag the data manually and this is not a problem\n",
    "projects = [\"Authentifizierung\", \"Angular\", \"Apex\", \"MySQL_PoC\", \"DOAG_Vortrag\", \"DS-R-L\", \"Sentimentanalyse\"]\n",
    "durations = [\"8h\", \"3h\", \"1d\", \"5_Std\", \"30_Min\"]\n",
    "#tasks = [\"Slides\", \"Impl\", \"Planung\", \"Recherche\", \"Implementierung\", \"Tests\", \"Unit\", \"Tests\", \"New_Features\",\n",
    "#         \"Auswertung\", \"Präsi\"]\n",
    "tasks = [\"Slides\", \"Impl\", \"Planung\", \"Recherche\", \"Implementierung\", \"Tests\", \"Unit_Tests\", \"New_Features\",\n",
    "         \"Auswertung\", \"Präsi\"]\n",
    "seps1 = [\"für\", \"auf\"]\n",
    "seps2 = [\":\"]\n",
    "seps3 = [\",\"]\n",
    "\n",
    "tag_to_ix = {\"duration\": 0, \"task\": 1, \"project\": 2, \"SEP\": 3}\n",
    "ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
    "\n",
    "words = projects + durations + tasks + seps1 + seps2 + seps3\n",
    "word_to_ix = {word : index for index, word in enumerate(words)}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [d + \" \" + t + \" \" + s + \" \" + p for d in durations for t in tasks for p in projects for s in seps1]\n",
    "len(s1)\n",
    "s1_tags = len(s1) * [[\"duration\", \"task\", \"SEP\", \"project\"]]\n",
    "s1\n",
    "#len(s1_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = [p + s + \" \" + t + \" \" + d for p in projects for s in seps2 for t in tasks for d in durations]\n",
    "s2_tags = len(s2) * [[\"project\", \"SEP\", \"task\", \"duration\"]]\n",
    "len(s2_tags)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = [p + s + \" \" + t + s + \" \" + d for p in projects for s in seps3 for t in tasks for d in durations]\n",
    "s3_tags = len(s3) * [[\"project\", \"SEP\", \"task\", \"SEP\", \"duration\"]]\n",
    "len(s3_tags)\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list(zip([word_tokenize(s) for s in s1+s2+s3], s1_tags + s2_tags + s3_tags))\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.choice([True, False], size=len(data), p = [0.8,0.2])\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.array(data)\n",
    "data_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_array[inds]\n",
    "test_data = data_array[np.logical_not(inds)]\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return Variable(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # LSTM(input_size = num features, hidden_size, num_layers)\n",
    "        # embedding size == number of features!\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "                Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        #print(embeds)                              # 4*6 for sentence 1\n",
    "        #print(embeds.view(len(sentence),1,-1))     # 4*1*6 for sentence 1\n",
    "        # LSTM input data format: (seq_len = num timesteps, batch, input_size = num_features)\n",
    "        # output: out == all hidden states, hidden == most recent hidden state \n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        #print(tag_space)                            # 4*4\n",
    "        tag_scores = F.log_softmax(tag_space)       # 4*4\n",
    "        return tag_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exists = False\n",
    "if not model_exists:\n",
    "    model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "else:\n",
    "    model = torch.load('model.sav')\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_exists:\n",
    "    for epoch in range(num_epochs):  \n",
    "        print\n",
    "        print(\"Epoch: {}\".format(str(epoch)))\n",
    "        for sentence, tags in train_data:\n",
    "\n",
    "            #print(sentence)\n",
    "\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Also, we need to clear out the hidden state of the LSTM,\n",
    "            # detaching it from its history on the last instance.\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Variables of word indices.\n",
    "            sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "            targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "            # Step 3. Run our forward pass.\n",
    "            tag_scores = model(sentence_in)\n",
    "\n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            loss = loss_function(tag_scores, targets)\n",
    "            print(round(loss.data[0],6))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_exists: torch.save(model, 'model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the scores are after training\n",
    "print(train_data[0][0])\n",
    "inputs = prepare_sequence(train_data[0][0], word_to_ix)\n",
    "tag_scores = model(inputs)\n",
    "# i,j corresponds to score for tag j for word i. The predicted tag is the maximum scoring tag.\n",
    "print(tag_scores.data)\n",
    "_, predicted = torch.max(tag_scores.data, 1)\n",
    "\n",
    "predicted = predicted.tolist()\n",
    "predicted  = [val for sublist in predicted for val in sublist]\n",
    "pred_tags = [ix_to_tag[p] for p in predicted]\n",
    "pred_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train_data)\n",
    "n_correct = 0\n",
    "for t in train_data:\n",
    "    inputs = prepare_sequence(t[0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    _, predicted = torch.max(tag_scores.data,1)\n",
    "    predicted = [val for sublist in predicted.tolist() for val in sublist]\n",
    "    pred_tags = [ix_to_tag[p] for p in predicted]\n",
    "    if pred_tags == t[1]: \n",
    "        n_correct = n_correct + 1\n",
    "    else: \n",
    "        print(t[0])\n",
    "        print(t[1])\n",
    "        print(pred_tags)\n",
    "        print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_train, n_correct, round(n_correct/n_train,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(test_data)\n",
    "n_correct = 0\n",
    "for t in test_data:\n",
    "    inputs = prepare_sequence(t[0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    _, predicted = torch.max(tag_scores.data,1)\n",
    "    predicted = [val for sublist in predicted.tolist() for val in sublist]\n",
    "    pred_tags = [ix_to_tag[p] for p in predicted]\n",
    "    #if pred_tags == t[1]: \n",
    "    n_correct = n_correct + 1\n",
    "    #else: \n",
    "    print(t[0])\n",
    "    print(t[1])\n",
    "    print(pred_tags)\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_test, n_correct, round(n_correct/n_test,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
